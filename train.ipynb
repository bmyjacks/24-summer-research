{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from model import GeneExpressionPredictionModel"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ],
   "id": "24c2a6b76d346b58",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load data\n",
    "fp_data = pd.read_csv('data/fingerprints.csv').values\n",
    "cp_data = pd.read_csv('data/descriptors.csv').values\n",
    "gene_data = pd.read_csv('data/genes.csv').values\n",
    "\n",
    "print(fp_data.shape, cp_data.shape, gene_data.shape)"
   ],
   "id": "ac6bc61e8f4d1554",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Split data\n",
    "fp_train, fp_test, cp_train, cp_test, gene_train, gene_test = train_test_split(\n",
    "    fp_data, cp_data, gene_data, test_size=0.2, random_state=42\n",
    ")"
   ],
   "id": "51be710f3960073f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Data loaders\n",
    "def get_data_loader(fp, cp, gene, batch_size):\n",
    "    dataset = TensorDataset(\n",
    "        torch.tensor(fp, dtype=torch.float32).to(device),\n",
    "        torch.tensor(cp, dtype=torch.float32).to(device),\n",
    "        torch.tensor(gene, dtype=torch.float32).to(device)\n",
    "    )\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ],
   "id": "843954d251e75e23",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calculate mean PCC\n",
    "def get_mean_pcc(model, data_loader):\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        pccs = []\n",
    "        for fp, cp, gene in data_loader:\n",
    "            output = model(fp, cp)\n",
    "            pcc = np.corrcoef(output.cpu().detach().numpy().flatten(), gene.cpu().detach().numpy().flatten())[0, 1]\n",
    "            pccs.append(pcc)\n",
    "\n",
    "        return np.mean(pccs)"
   ],
   "id": "4fabed4c50455b92",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)"
   ],
   "id": "c9dd177cedfc595f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize\n",
    "model = GeneExpressionPredictionModel().to(device)\n",
    "model.apply(initialize_weights)\n",
    "\n",
    "train_pccs, train_losses, cv_pccs, test_pccs = [], [], [], []"
   ],
   "id": "1503caaab40c0da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Training func\n",
    "def train(model, train_loader, cv_loader, test_loader, optimizer, loss_func, epochs=10, patience=20):\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_loss = np.inf\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    epoch_losses, epoch_train_pccs, epoch_val_pccs, epoch_test_pccs = [], [], [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "\n",
    "        total_loss = .0\n",
    "\n",
    "        for fp, cp, gene in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.autocast(device_type=device.type):\n",
    "                output = model(fp, cp)\n",
    "                loss = loss_func(output, gene)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * fp.size(0)\n",
    "\n",
    "        epoch_loss = total_loss / len(train_loader.dataset)\n",
    "        epoch_losses.append(epoch_loss)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.inference_mode():\n",
    "            train_pcc = get_mean_pcc(model, train_loader)\n",
    "            epoch_train_pccs.append(train_pcc)\n",
    "\n",
    "            cv_pcc = get_mean_pcc(model, cv_loader)\n",
    "            epoch_val_pccs.append(cv_pcc)\n",
    "\n",
    "            test_pcc = get_mean_pcc(model, test_loader)\n",
    "            epoch_test_pccs.append(test_pcc)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(\n",
    "                f'Epoch {epoch + 1}/{epochs} - Loss: {epoch_loss:.4f} - Train PCC: {train_pcc:.4f} - Val PCC: {cv_pcc:.4f} - Test PCC: {test_pcc:.4f}')\n",
    "\n",
    "        if best_loss - epoch_loss > 1e-3:\n",
    "            best_loss = epoch_loss\n",
    "            best_model_wts = model.state_dict()\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f'Early stopping at epoch {epoch + 1}')\n",
    "            break\n",
    "\n",
    "    train_losses.append(epoch_losses)\n",
    "    train_pccs.append(epoch_train_pccs)\n",
    "    cv_pccs.append(epoch_val_pccs)\n",
    "    test_pccs.append(epoch_test_pccs)\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    # torch.save(model.state_dict(), 'model.pt')\n",
    "\n",
    "    return model"
   ],
   "id": "a6ebefc9b380f534",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# KFold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)"
   ],
   "id": "40601cfb5a9347fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Train\n",
    "for train_index, cv_index in kf.split(fp_train):\n",
    "    batch_size = 16\n",
    "\n",
    "    train_loader = get_data_loader(fp_train[train_index], cp_train[train_index], gene_train[train_index],\n",
    "                                   batch_size=batch_size)\n",
    "    cv_loader = get_data_loader(fp_train[cv_index], cp_train[cv_index], gene_train[cv_index], batch_size=batch_size)\n",
    "    test_loader = get_data_loader(fp_test, cp_test, gene_test, batch_size=batch_size)\n",
    "\n",
    "    model = GeneExpressionPredictionModel().to(device)\n",
    "    model = train(model, train_loader, cv_loader, test_loader, optimizer=torch.optim.Adam(model.parameters(), lr=1e-5),\n",
    "                  loss_func=nn.MSELoss(), epochs=200, patience=10)"
   ],
   "id": "b1ef10ef9630c748",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create a figure with four subplots\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(16, 8))\n",
    "\n",
    "# Plot train_loss on the first subplot\n",
    "for i, loss_values in enumerate(train_losses):\n",
    "    ax1.plot(range(1, len(loss_values) + 1), loss_values, label=f'Fold {i + 1}')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Train loss over Epochs for each Fold')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot train_pcc on the second subplot\n",
    "for i, pcc_values in enumerate(train_pccs):\n",
    "    ax2.plot(range(1, len(pcc_values) + 1), pcc_values, label=f'Fold {i + 1}')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('PCC')\n",
    "ax2.set_title('Train PCC over Epochs for each Fold')\n",
    "ax2.legend()\n",
    "\n",
    "# Plot val_pcc on the third subplot\n",
    "for i, pcc_values in enumerate(cv_pccs):\n",
    "    ax3.plot(range(1, len(pcc_values) + 1), pcc_values, label=f'Fold {i + 1}')\n",
    "ax3.set_xlabel('Epochs')\n",
    "ax3.set_ylabel('PCC')\n",
    "ax3.set_title('Validation PCC over Epochs for each Fold')\n",
    "ax3.legend()\n",
    "\n",
    "# Plot test_pcc on the fourth subplot\n",
    "for i, pcc_values in enumerate(test_pccs):\n",
    "    ax4.plot(range(1, len(pcc_values) + 1), pcc_values, label=f'Fold {i + 1}')\n",
    "ax4.set_xlabel('Epochs')\n",
    "ax4.set_ylabel('PCC')\n",
    "ax4.set_title('Test PCC over Epochs for each Fold')\n",
    "ax4.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "ee800a0b8522cdce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "8050885d20e2d495",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
